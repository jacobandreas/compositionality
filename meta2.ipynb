{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cls2_data.data import Dataset\n",
    "import evals\n",
    "from util import Logger\n",
    "\n",
    "import editdistance\n",
    "import numpy as np\n",
    "import sexpdata\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler as opt_sched\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EMBED = 128\n",
    "N_HIDDEN = 256\n",
    "N_BATCH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(var):\n",
    "    return var.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self._conv_part = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self._fc_part = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self._pred_part = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self._loss = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        n_batch, n_ex, c, w, h = batch.feats_in.shape\n",
    "        conv_in = self._conv_part(batch.feats_in.view(n_batch * n_ex, c, w, h))\n",
    "        fc_in = self._fc_part(conv_in.view(n_batch * n_ex, 16*5*5))\n",
    "        #fc_in += 0 * Variable(torch.randn(fc_in.shape))\n",
    "        predictor = self._pred_part(fc_in.view(n_batch, n_ex, 64).sum(dim=1))\n",
    "        #predictor += 0.0 * Variable(torch.randn(predictor.shape))\n",
    "        \n",
    "        conv_out = self._conv_part(batch.feats_out)\n",
    "        rep_out = self._fc_part(conv_out.view(n_batch, 16*5*5))\n",
    "        #print(predictor[0])\n",
    "        #print(rep_out[0])\n",
    "        \n",
    "        score = (predictor * rep_out).sum(dim=1)\n",
    "        #print(score)\n",
    "        labels = (score > 0).float()\n",
    "        loss = self._loss(score, batch.label_out)\n",
    "        \n",
    "        return loss, (labels == batch.label_out).float().mean(), labels, predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_isom_tree(reps, lfs):\n",
    "    return evals.isom(reps, lfs, evals.cos_dist, evals.tree_dist)\n",
    "\n",
    "def eval_isom_ext(reps, exts):\n",
    "    return evals.isom(reps, exts, evals.cos_dist, evals.l1_dist)\n",
    "\n",
    "def eval_hom(model, reps1, reps2):\n",
    "    #sim_rep = lambda x, y: ((x-y)**2).sum()\n",
    "    return evals.hom(reps1, reps2, None)\n",
    "\n",
    "def info(reps):\n",
    "    buckets = np.zeros((64, 10))\n",
    "    for rep in reps:\n",
    "        for i in range(len(rep)):\n",
    "            bucket = 5 + int(rep[i] * 10)\n",
    "            bucket = max(bucket, 0)\n",
    "            bucket = min(bucket, 9)\n",
    "            buckets[i, bucket] += 1\n",
    "    buckets += 1e-7\n",
    "    probs = buckets / buckets.sum(axis=1, keepdims=True)\n",
    "    logprobs = np.log(probs)\n",
    "    entropies = -(probs * logprobs).sum(axis=1)\n",
    "    return entropies.mean()\n",
    "\n",
    "EPOCH = 'epoch'\n",
    "TRN_LOSS = 'trn loss'\n",
    "TRN_ACC = 'trn acc'\n",
    "VAL_ACC = 'val acc'\n",
    "CVAL_ACC = 'cval acc'\n",
    "INFO_TX = 'I(T;X)'\n",
    "ISOM_TREE = 'isom (r-t)'\n",
    "ISOM_EXT = 'isom (r-e)'\n",
    "ISOM_CHK = 'isom (t-e)'\n",
    "HOM = 'hom'\n",
    "CHOM = 'c_hom'\n",
    "LOG_KEYS = [EPOCH, TRN_LOSS, TRN_ACC, VAL_ACC, CVAL_ACC, HOM,   CHOM,  INFO_TX]\n",
    "LOG_FMTS = ['d',   '.3f',    '.3f',   '.3f',   '.3f',    '.3f', '.3f', '.3f']\n",
    "\n",
    "def validate(dataset, model, logger):\n",
    "    val_batch = dataset.get_val_batch()\n",
    "    _, val_acc, _, val_reps = model(val_batch)\n",
    "    val_acc, = unwrap(val_acc)\n",
    "    logger.update(VAL_ACC, val_acc)\n",
    "    \n",
    "    cval_batch = dataset.get_cval_batch()\n",
    "    _, cval_acc, _, cval_reps = model(cval_batch)\n",
    "    cval_acc, = unwrap(cval_acc)\n",
    "    logger.update(CVAL_ACC, cval_acc)\n",
    "    \n",
    "    prim_batch = dataset.get_prim_batch()\n",
    "    _, _, _, prim_reps = model(prim_batch)\n",
    "    \n",
    "    comp = evals.comp_eval(\n",
    "        prim_reps.data.numpy(), prim_batch.lf, \n",
    "        val_reps.data.numpy(), val_batch.lf, \n",
    "        lambda x, y: (x+y), \n",
    "        evals.cos_dist)\n",
    "    logger.update(HOM, np.mean(comp))\n",
    "    \n",
    "    ccomp = evals.comp_eval(\n",
    "        prim_reps.data.numpy(), prim_batch.lf,\n",
    "        cval_reps.data.numpy(), cval_batch.lf,\n",
    "        lambda x, y: (x+y),\n",
    "        evals.cos_dist)\n",
    "    logger.update(CHOM, np.mean(ccomp))\n",
    "    \n",
    "    logger.update(INFO_TX, info(val_reps))\n",
    "    \n",
    "    return val_acc\n",
    "\n",
    "def train(dataset, model):\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    sched = opt_sched.ReduceLROnPlateau(opt, factor=0.5, verbose=True, mode='max')\n",
    "    logger = Logger(LOG_KEYS, LOG_FMTS, width=10)\n",
    "    logger.begin()\n",
    "    \n",
    "    val_acc = validate(dataset, model, logger)\n",
    "    logger.print()\n",
    "    \n",
    "    for i in range(100):\n",
    "        trn_loss = 0\n",
    "        trn_acc = 0\n",
    "        for j in range(100):\n",
    "            batch = dataset.get_train_batch(N_BATCH)\n",
    "            loss, acc, _, _ = model(batch)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            trn_loss += unwrap(loss)[0]\n",
    "            trn_acc += unwrap(acc)[0]\n",
    "        trn_loss /= 100\n",
    "        trn_acc /= 100\n",
    "        \n",
    "        logger.update(EPOCH, i)\n",
    "        logger.update(TRN_LOSS, trn_loss)\n",
    "        logger.update(TRN_ACC, trn_acc)\n",
    "        val_acc = validate(dataset, model, logger)\n",
    "        sched.step(val_acc)\n",
    "        logger.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      epoch |   trn loss |    trn acc |    val acc |   cval acc |        hom |      c_hom |     I(T;X) |\n",
      "|            |            |            |      0.480 |      0.533 |      0.029 |      0.023 |      0.263 |\n",
      "|          0 |      0.663 |      0.592 |      0.672 |      0.709 |      0.355 |      0.276 |      1.398 |\n",
      "|          1 |      0.644 |      0.639 |      0.682 |      0.713 |      0.357 |      0.293 |      1.415 |\n",
      "|          2 |      0.602 |      0.681 |      0.726 |      0.711 |      0.449 |      0.418 |      1.681 |\n",
      "|          3 |      0.590 |      0.689 |      0.704 |      0.669 |      0.410 |      0.406 |      1.666 |\n",
      "|          4 |      0.586 |      0.691 |      0.718 |      0.699 |      0.419 |      0.382 |      1.780 |\n",
      "|          5 |      0.569 |      0.705 |      0.704 |      0.722 |      0.433 |      0.372 |      1.775 |\n",
      "|          6 |      0.561 |      0.709 |      0.720 |      0.720 |      0.402 |      0.358 |      1.854 |\n",
      "|          7 |      0.560 |      0.716 |      0.710 |      0.697 |      0.382 |      0.362 |      1.738 |\n",
      "|          8 |      0.545 |      0.730 |      0.734 |      0.728 |      0.382 |      0.335 |      1.841 |\n"
     ]
    }
   ],
   "source": [
    "#dataset = Dataset()\n",
    "model = Model(dataset)\n",
    "train(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
