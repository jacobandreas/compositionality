{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data import Dataset\n",
    "import evals\n",
    "\n",
    "import editdistance\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler as opt_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BATCH = 256\n",
    "N_EMBED = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(var):\n",
    "    return var.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self._emb = nn.Embedding(dataset.n_vocab, N_EMBED)\n",
    "        self._pred = nn.Linear(N_EMBED, dataset.n_vocab)\n",
    "        self._loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        emb = self._emb(batch.ctx)\n",
    "        hid = emb.sum(dim=1)\n",
    "        logits = self._pred(hid)\n",
    "        loss = self._loss(logits, batch.tgt)\n",
    "        return loss\n",
    "    \n",
    "    def represent(self, indices):\n",
    "        return self._pred.weight[indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2dist(x, y):\n",
    "    return ((x-y)**2).sum()\n",
    "\n",
    "def cos_dist(x, y):\n",
    "    return 1 - ((x/np.linalg.norm(x) * y/np.linalg.norm(y))).sum()\n",
    "\n",
    "def eval_metric(reps, words):\n",
    "    sim_rep = cos_dist\n",
    "    #sim_lf = editdistance.eval\n",
    "    sim_word = lambda x, y: 2 - (len(set(x.split('__')) & set(y.split('__'))))\n",
    "    return evals.metric(words, reps, sim_word, sim_rep)\n",
    "\n",
    "def eval_hom(preds, trues):\n",
    "    return evals.hom(preds, trues, cos_dist)\n",
    "\n",
    "class Logger(object):\n",
    "    EPOCH = 'epoch'\n",
    "    TRN_LOSS = 'trn loss'\n",
    "    METRIC = 'metric'\n",
    "    HOM = 'hom'\n",
    "    KEYS = [EPOCH, TRN_LOSS, METRIC, HOM]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "    \n",
    "    def begin(self):\n",
    "        print('| ' + ' | '.join('%12s' % k for k in self.KEYS) + ' |')\n",
    "        \n",
    "    def update(self, key, value):\n",
    "        assert key not in self.data\n",
    "        self.data[key] = value\n",
    "        \n",
    "    def print(self):\n",
    "        print('| ' + ' | '.join('%12.3f' % self.data[k] for k in self.KEYS) + ' |')\n",
    "        self.data.clear()\n",
    "        \n",
    "def validate(dataset, model, logger):\n",
    "    comp_batch = dataset.get_comp_batch()\n",
    "    reps_bi = unwrap(model.represent(comp_batch.bi))\n",
    "    reps_pred = unwrap(model.represent(comp_batch.uni1) + model.represent(comp_batch.uni2))\n",
    "    words_bi = [dataset.unencode(i) for i in comp_batch.bi]\n",
    "    logger.update(Logger.METRIC, eval_metric(reps_bi, words_bi))\n",
    "    logger.update(Logger.HOM, eval_hom(reps_pred, reps_bi))\n",
    "\n",
    "def train(dataset, model):\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    sched = opt_sched.ReduceLROnPlateau(opt, factor=0.5, verbose=True, mode='max')\n",
    "    logger = Logger()\n",
    "    logger.begin()\n",
    "    \n",
    "    for i in range(100):\n",
    "        trn_loss = 0\n",
    "        for j in range(10):\n",
    "            batch = dataset.get_batch(N_BATCH)\n",
    "            loss = model(batch)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            trn_loss += unwrap(loss)[0]\n",
    "        trn_loss /= 100\n",
    "        \n",
    "        logger.update(logger.EPOCH, i)\n",
    "        logger.update(logger.TRN_LOSS, trn_loss)\n",
    "        validate(dataset, model, logger)\n",
    "        #sched.step(val_acc)\n",
    "        logger.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|        epoch |     trn loss |       metric |          hom |\n",
      "|        0.000 |        1.285 |        0.080 |        0.994 |\n",
      "|        1.000 |        1.196 |        0.083 |        0.994 |\n",
      "|        2.000 |        1.075 |        0.088 |        0.993 |\n",
      "|        3.000 |        0.973 |        0.088 |        0.991 |\n",
      "|        4.000 |        0.923 |        0.084 |        0.988 |\n",
      "|        5.000 |        0.903 |        0.084 |        0.986 |\n",
      "|        6.000 |        0.878 |        0.087 |        0.982 |\n",
      "|        7.000 |        0.851 |        0.091 |        0.979 |\n",
      "|        8.000 |        0.855 |        0.092 |        0.975 |\n",
      "|        9.000 |        0.869 |        0.091 |        0.970 |\n",
      "|       10.000 |        0.836 |        0.093 |        0.966 |\n",
      "|       11.000 |        0.845 |        0.095 |        0.962 |\n",
      "|       12.000 |        0.836 |        0.097 |        0.958 |\n",
      "|       13.000 |        0.828 |        0.100 |        0.954 |\n",
      "|       14.000 |        0.825 |        0.102 |        0.950 |\n",
      "|       15.000 |        0.824 |        0.103 |        0.945 |\n",
      "|       16.000 |        0.821 |        0.103 |        0.943 |\n",
      "|       17.000 |        0.816 |        0.106 |        0.939 |\n",
      "|       18.000 |        0.814 |        0.107 |        0.935 |\n",
      "|       19.000 |        0.804 |        0.109 |        0.931 |\n",
      "|       20.000 |        0.804 |        0.108 |        0.927 |\n",
      "|       21.000 |        0.794 |        0.107 |        0.925 |\n",
      "|       22.000 |        0.798 |        0.112 |        0.922 |\n",
      "|       23.000 |        0.798 |        0.114 |        0.920 |\n",
      "|       24.000 |        0.787 |        0.114 |        0.916 |\n",
      "|       25.000 |        0.788 |        0.116 |        0.914 |\n",
      "|       26.000 |        0.783 |        0.113 |        0.911 |\n",
      "|       27.000 |        0.791 |        0.115 |        0.908 |\n",
      "|       28.000 |        0.772 |        0.117 |        0.905 |\n",
      "|       29.000 |        0.785 |        0.120 |        0.902 |\n",
      "|       30.000 |        0.770 |        0.120 |        0.899 |\n",
      "|       31.000 |        0.770 |        0.120 |        0.896 |\n",
      "|       32.000 |        0.764 |        0.120 |        0.892 |\n",
      "|       33.000 |        0.773 |        0.123 |        0.888 |\n",
      "|       34.000 |        0.761 |        0.124 |        0.885 |\n",
      "|       35.000 |        0.760 |        0.128 |        0.883 |\n",
      "|       36.000 |        0.764 |        0.128 |        0.882 |\n",
      "|       37.000 |        0.765 |        0.128 |        0.880 |\n",
      "|       38.000 |        0.758 |        0.129 |        0.878 |\n",
      "|       39.000 |        0.764 |        0.128 |        0.877 |\n",
      "|       40.000 |        0.745 |        0.125 |        0.874 |\n",
      "|       41.000 |        0.755 |        0.126 |        0.871 |\n",
      "|       42.000 |        0.752 |        0.127 |        0.869 |\n",
      "|       43.000 |        0.742 |        0.128 |        0.867 |\n",
      "|       44.000 |        0.747 |        0.127 |        0.864 |\n",
      "|       45.000 |        0.737 |        0.128 |        0.861 |\n",
      "|       46.000 |        0.741 |        0.127 |        0.859 |\n",
      "|       47.000 |        0.741 |        0.128 |        0.857 |\n",
      "|       48.000 |        0.731 |        0.132 |        0.855 |\n",
      "|       49.000 |        0.734 |        0.132 |        0.852 |\n",
      "|       50.000 |        0.722 |        0.130 |        0.850 |\n",
      "|       51.000 |        0.724 |        0.131 |        0.848 |\n",
      "|       52.000 |        0.736 |        0.132 |        0.846 |\n",
      "|       53.000 |        0.725 |        0.131 |        0.844 |\n",
      "|       54.000 |        0.722 |        0.131 |        0.842 |\n",
      "|       55.000 |        0.725 |        0.129 |        0.840 |\n",
      "|       56.000 |        0.715 |        0.128 |        0.838 |\n",
      "|       57.000 |        0.722 |        0.130 |        0.837 |\n",
      "|       58.000 |        0.722 |        0.130 |        0.837 |\n",
      "|       59.000 |        0.722 |        0.132 |        0.835 |\n",
      "|       60.000 |        0.708 |        0.132 |        0.833 |\n",
      "|       61.000 |        0.719 |        0.134 |        0.832 |\n",
      "|       62.000 |        0.723 |        0.134 |        0.830 |\n",
      "|       63.000 |        0.718 |        0.134 |        0.828 |\n",
      "|       64.000 |        0.706 |        0.134 |        0.826 |\n",
      "|       65.000 |        0.701 |        0.136 |        0.825 |\n",
      "|       66.000 |        0.708 |        0.137 |        0.823 |\n",
      "|       67.000 |        0.709 |        0.137 |        0.822 |\n",
      "|       68.000 |        0.704 |        0.137 |        0.820 |\n",
      "|       69.000 |        0.707 |        0.138 |        0.818 |\n",
      "|       70.000 |        0.704 |        0.139 |        0.816 |\n",
      "|       71.000 |        0.705 |        0.138 |        0.816 |\n",
      "|       72.000 |        0.700 |        0.139 |        0.815 |\n",
      "|       73.000 |        0.699 |        0.141 |        0.814 |\n",
      "|       74.000 |        0.695 |        0.142 |        0.813 |\n",
      "|       75.000 |        0.687 |        0.142 |        0.811 |\n",
      "|       76.000 |        0.697 |        0.142 |        0.809 |\n",
      "|       77.000 |        0.693 |        0.143 |        0.807 |\n",
      "|       78.000 |        0.690 |        0.145 |        0.806 |\n",
      "|       79.000 |        0.686 |        0.146 |        0.803 |\n",
      "|       80.000 |        0.690 |        0.147 |        0.801 |\n",
      "|       81.000 |        0.686 |        0.147 |        0.799 |\n",
      "|       82.000 |        0.678 |        0.149 |        0.797 |\n",
      "|       83.000 |        0.690 |        0.150 |        0.796 |\n",
      "|       84.000 |        0.684 |        0.150 |        0.795 |\n",
      "|       85.000 |        0.684 |        0.149 |        0.794 |\n",
      "|       86.000 |        0.691 |        0.150 |        0.792 |\n",
      "|       87.000 |        0.675 |        0.151 |        0.791 |\n",
      "|       88.000 |        0.674 |        0.152 |        0.790 |\n",
      "|       89.000 |        0.669 |        0.153 |        0.789 |\n",
      "|       90.000 |        0.672 |        0.153 |        0.788 |\n",
      "|       91.000 |        0.674 |        0.153 |        0.787 |\n",
      "|       92.000 |        0.671 |        0.153 |        0.785 |\n",
      "|       93.000 |        0.676 |        0.154 |        0.783 |\n",
      "|       94.000 |        0.668 |        0.153 |        0.781 |\n",
      "|       95.000 |        0.674 |        0.150 |        0.780 |\n",
      "|       96.000 |        0.673 |        0.151 |        0.778 |\n",
      "|       97.000 |        0.668 |        0.151 |        0.776 |\n",
      "|       98.000 |        0.660 |        0.152 |        0.774 |\n",
      "|       99.000 |        0.655 |        0.152 |        0.773 |\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "model = Model(dataset)\n",
    "train(dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 99.000 |        0.614 |        0.129 |        0.834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
