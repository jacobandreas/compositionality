{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data import Dataset\n",
    "import evals\n",
    "\n",
    "import editdistance\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler as opt_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BATCH = 256\n",
    "N_EMBED = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(var):\n",
    "    return var.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self._emb = nn.Embedding(dataset.n_vocab, N_EMBED)\n",
    "        self._pred = nn.Linear(N_EMBED, dataset.n_vocab)\n",
    "        self._loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        emb = self._emb(batch.ctx)\n",
    "        hid = emb.sum(dim=1)\n",
    "        logits = self._pred(hid)\n",
    "        loss = self._loss(logits, batch.tgt)\n",
    "        return loss\n",
    "    \n",
    "    def represent(self, indices):\n",
    "        return self._pred.weight[indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2dist(x, y):\n",
    "    return ((x-y)**2).sum()\n",
    "\n",
    "def cos_dist(x, y):\n",
    "    return 1 - ((x/np.linalg.norm(x) * y/np.linalg.norm(y))).sum()\n",
    "\n",
    "def eval_metric(reps, words):\n",
    "    sim_rep = cos_sim\n",
    "    #sim_lf = editdistance.eval\n",
    "    sim_word = lambda x, y: 2 - (len(set(x.split('__')) & set(y.split('__'))))\n",
    "    return evals.metric(words, reps, sim_word, sim_rep)\n",
    "\n",
    "def eval_hom(preds, trues):\n",
    "    return evals.hom(preds, trues, cos_dist)\n",
    "\n",
    "class Logger(object):\n",
    "    EPOCH = 'epoch'\n",
    "    TRN_LOSS = 'trn loss'\n",
    "    METRIC = 'metric'\n",
    "    HOM = 'hom'\n",
    "    KEYS = [EPOCH, TRN_LOSS, METRIC, HOM]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "    \n",
    "    def begin(self):\n",
    "        print('| ' + ' | '.join('%12s' % k for k in self.KEYS) + ' |')\n",
    "        \n",
    "    def update(self, key, value):\n",
    "        assert key not in self.data\n",
    "        self.data[key] = value\n",
    "        \n",
    "    def print(self):\n",
    "        print('| ' + ' | '.join('%12.3f' % self.data[k] for k in self.KEYS) + ' |')\n",
    "        self.data.clear()\n",
    "        \n",
    "def validate(dataset, model, logger):\n",
    "    comp_batch = dataset.get_comp_batch()\n",
    "    reps_bi = unwrap(model.represent(comp_batch.bi))\n",
    "    reps_pred = unwrap(model.represent(comp_batch.uni1) + model.represent(comp_batch.uni2))\n",
    "    words_bi = [dataset.unencode(i) for i in comp_batch.bi]\n",
    "    logger.update(Logger.METRIC, eval_metric(reps_bi, words_bi))\n",
    "    logger.update(Logger.HOM, eval_hom(reps_pred, reps_bi))\n",
    "\n",
    "def train(dataset, model):\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    sched = opt_sched.ReduceLROnPlateau(opt, factor=0.5, verbose=True, mode='max')\n",
    "    logger = Logger()\n",
    "    logger.begin()\n",
    "    \n",
    "    for i in range(100):\n",
    "        trn_loss = 0\n",
    "        for j in range(10):\n",
    "            batch = dataset.get_batch(N_BATCH)\n",
    "            loss = model(batch)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            trn_loss += unwrap(loss)[0]\n",
    "        trn_loss /= 100\n",
    "        \n",
    "        logger.update(logger.EPOCH, i)\n",
    "        logger.update(logger.TRN_LOSS, trn_loss)\n",
    "        validate(dataset, model, logger)\n",
    "        #sched.step(val_acc)\n",
    "        logger.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|        epoch |     trn loss |       metric |          hom |\n",
      "|        0.000 |        0.817 |        0.076 |        0.976 |\n",
      "|        1.000 |        0.825 |        0.070 |        0.963 |\n",
      "|        2.000 |        0.806 |        0.073 |        0.955 |\n",
      "|        3.000 |        0.781 |        0.081 |        0.950 |\n",
      "|        4.000 |        0.760 |        0.086 |        0.945 |\n",
      "|        5.000 |        0.741 |        0.087 |        0.942 |\n",
      "|        6.000 |        0.727 |        0.087 |        0.938 |\n",
      "|        7.000 |        0.724 |        0.083 |        0.932 |\n",
      "|        8.000 |        0.724 |        0.087 |        0.930 |\n",
      "|        9.000 |        0.710 |        0.096 |        0.928 |\n",
      "|       10.000 |        0.717 |        0.101 |        0.925 |\n",
      "|       11.000 |        0.715 |        0.102 |        0.924 |\n",
      "|       12.000 |        0.703 |        0.102 |        0.920 |\n",
      "|       13.000 |        0.696 |        0.104 |        0.917 |\n",
      "|       14.000 |        0.690 |        0.101 |        0.915 |\n",
      "|       15.000 |        0.699 |        0.102 |        0.913 |\n",
      "|       16.000 |        0.708 |        0.103 |        0.909 |\n",
      "|       17.000 |        0.686 |        0.104 |        0.906 |\n",
      "|       18.000 |        0.690 |        0.105 |        0.904 |\n",
      "|       19.000 |        0.690 |        0.111 |        0.903 |\n",
      "|       20.000 |        0.684 |        0.113 |        0.905 |\n",
      "|       21.000 |        0.680 |        0.112 |        0.904 |\n",
      "|       22.000 |        0.682 |        0.111 |        0.903 |\n",
      "|       23.000 |        0.677 |        0.103 |        0.899 |\n",
      "|       24.000 |        0.684 |        0.103 |        0.897 |\n",
      "|       25.000 |        0.672 |        0.106 |        0.896 |\n",
      "|       26.000 |        0.672 |        0.108 |        0.895 |\n",
      "|       27.000 |        0.671 |        0.113 |        0.894 |\n",
      "|       28.000 |        0.677 |        0.114 |        0.893 |\n",
      "|       29.000 |        0.668 |        0.113 |        0.891 |\n",
      "|       30.000 |        0.661 |        0.115 |        0.890 |\n",
      "|       31.000 |        0.662 |        0.116 |        0.890 |\n",
      "|       32.000 |        0.676 |        0.114 |        0.888 |\n",
      "|       33.000 |        0.660 |        0.116 |        0.887 |\n",
      "|       34.000 |        0.660 |        0.118 |        0.886 |\n",
      "|       35.000 |        0.662 |        0.117 |        0.883 |\n",
      "|       36.000 |        0.655 |        0.117 |        0.881 |\n",
      "|       37.000 |        0.657 |        0.121 |        0.880 |\n",
      "|       38.000 |        0.651 |        0.120 |        0.880 |\n",
      "|       39.000 |        0.654 |        0.117 |        0.879 |\n",
      "|       40.000 |        0.654 |        0.114 |        0.877 |\n",
      "|       41.000 |        0.661 |        0.117 |        0.876 |\n",
      "|       42.000 |        0.645 |        0.118 |        0.875 |\n",
      "|       43.000 |        0.654 |        0.119 |        0.875 |\n",
      "|       44.000 |        0.647 |        0.120 |        0.874 |\n",
      "|       45.000 |        0.645 |        0.123 |        0.872 |\n",
      "|       46.000 |        0.647 |        0.121 |        0.872 |\n",
      "|       47.000 |        0.652 |        0.124 |        0.871 |\n",
      "|       48.000 |        0.648 |        0.124 |        0.870 |\n",
      "|       49.000 |        0.652 |        0.124 |        0.870 |\n",
      "|       50.000 |        0.644 |        0.123 |        0.870 |\n",
      "|       51.000 |        0.635 |        0.123 |        0.870 |\n",
      "|       52.000 |        0.643 |        0.123 |        0.869 |\n",
      "|       53.000 |        0.643 |        0.125 |        0.867 |\n",
      "|       54.000 |        0.639 |        0.126 |        0.866 |\n",
      "|       55.000 |        0.632 |        0.126 |        0.864 |\n",
      "|       56.000 |        0.641 |        0.123 |        0.864 |\n",
      "|       57.000 |        0.635 |        0.122 |        0.862 |\n",
      "|       58.000 |        0.636 |        0.123 |        0.861 |\n",
      "|       59.000 |        0.635 |        0.122 |        0.861 |\n",
      "|       60.000 |        0.638 |        0.122 |        0.860 |\n",
      "|       61.000 |        0.634 |        0.123 |        0.858 |\n",
      "|       62.000 |        0.640 |        0.123 |        0.858 |\n",
      "|       63.000 |        0.633 |        0.124 |        0.857 |\n",
      "|       64.000 |        0.631 |        0.126 |        0.856 |\n",
      "|       65.000 |        0.630 |        0.127 |        0.856 |\n",
      "|       66.000 |        0.627 |        0.128 |        0.856 |\n",
      "|       67.000 |        0.626 |        0.127 |        0.856 |\n",
      "|       68.000 |        0.630 |        0.128 |        0.856 |\n",
      "|       69.000 |        0.627 |        0.126 |        0.854 |\n",
      "|       70.000 |        0.624 |        0.126 |        0.852 |\n",
      "|       71.000 |        0.622 |        0.127 |        0.850 |\n",
      "|       72.000 |        0.622 |        0.125 |        0.850 |\n",
      "|       73.000 |        0.628 |        0.125 |        0.850 |\n",
      "|       74.000 |        0.628 |        0.126 |        0.849 |\n",
      "|       75.000 |        0.623 |        0.124 |        0.848 |\n",
      "|       76.000 |        0.627 |        0.127 |        0.848 |\n",
      "|       77.000 |        0.617 |        0.129 |        0.846 |\n",
      "|       78.000 |        0.620 |        0.129 |        0.847 |\n",
      "|       79.000 |        0.621 |        0.129 |        0.847 |\n",
      "|       80.000 |        0.627 |        0.127 |        0.847 |\n",
      "|       81.000 |        0.628 |        0.126 |        0.846 |\n",
      "|       82.000 |        0.619 |        0.125 |        0.845 |\n",
      "|       83.000 |        0.621 |        0.126 |        0.845 |\n",
      "|       84.000 |        0.619 |        0.127 |        0.843 |\n",
      "|       85.000 |        0.612 |        0.126 |        0.842 |\n",
      "|       86.000 |        0.621 |        0.125 |        0.841 |\n",
      "|       87.000 |        0.607 |        0.127 |        0.841 |\n",
      "|       88.000 |        0.621 |        0.127 |        0.840 |\n",
      "|       89.000 |        0.625 |        0.127 |        0.840 |\n",
      "|       90.000 |        0.610 |        0.126 |        0.839 |\n",
      "|       91.000 |        0.610 |        0.127 |        0.838 |\n",
      "|       92.000 |        0.618 |        0.127 |        0.838 |\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "model = Model(dataset)\n",
    "train(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
